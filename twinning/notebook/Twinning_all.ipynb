{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Twinning_all.ipynb","provenance":[{"file_id":"1QZqrofI8Tv1LkJZkWLYdPNw-RGCkf2FV","timestamp":1566231191740}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ppo4IdehnwsX"},"source":["# predicting tyming of data"]},{"cell_type":"code","metadata":{"id":"39nMvLWcnCzM"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZg3YMxQpAPo"},"source":["cd drive/MyDrive/'Colab Notebooks'/eecs545/twinning"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sklearn as sk\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn \n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","\n","np.random.seed(1234)\n","\n","%matplotlib inline\n","def split(X, Y):\n","    Xtrain, Xtemp, Ytrain, Ytemp = train_test_split(X, Y, train_size = .7)\n","    Xtest, Xvalid, Ytest, Yvalid = train_test_split(Xtemp, Ytemp, train_size= .5)\n","    return Xtrain, Xvalid, Xtest, Ytrain, Yvalid, Ytest\n","\n","def MAPE(true, pred):\n","    return [(np.abs(pred[i] - y_test[i]).mean() / y_test[i].mean()).item() for i in range(len(true))]\n","\n","input_size = 6\n","output_size = 500"],"metadata":{"id":"x7Me0JaLHrSM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MLP(nn.Module):\n","  '''\n","    Multilayer Perceptron for regression.\n","  '''\n","  def __init__(self):\n","    super().__init__()\n","    self.layers = nn.Sequential(\n","      nn.Linear(input_size, 64),\n","      nn.BatchNorm1d(64),\n","      nn.Dropout(0.5),\n","      nn.ReLU(),\n","      nn.Linear(64, 32),\n","      nn.BatchNorm1d(32),\n","      nn.Dropout(0.5),\n","      nn.ReLU(),\n","      nn.Linear(32, 32),\n","      nn.BatchNorm1d(32),\n","      nn.Dropout(0.5),\n","      nn.ReLU(),\n","      nn.Linear(32, output_size)\n","    )\n","\n","\n","  def forward(self, x):\n","    '''\n","      Forward pass\n","    '''\n","    return self.layers(x)\n","\n","def train_model(dataloader, model, loss_fn, optimizer, epochs):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","\n","        # Compute prediction error\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if epochs % 10 == 0:\n","            if batch % 10 == 0:\n","                loss, current = loss.item(), batch * len(X)\n","                print(f\"Train loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","def test_model(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","    test_loss /= num_batches\n","    test_loss /= output_size\n","    print(f\"Val Error: \\n Avg loss: {test_loss:>8f} \\n\")\n","\n","def predict_model(X, model):\n","    with torch.no_grad():\n","        return model(X)"],"metadata":{"id":"yfI4j0lbzMUH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prepare data set"],"metadata":{"id":"plSsW6NBOx3e"}},{"cell_type":"code","source":["data = pd.read_csv(\"../data/transient_pred/scalar_res.csv\")\n","data = data.iloc[:, 0:6]\n","sscaler = StandardScaler()\n","# sscaler = MinMaxScaler()\n","X = sscaler.fit_transform(data)"],"metadata":{"id":"cJs7l0IysXXh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.shape"],"metadata":{"id":"Vn2mXCPpqWXw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_Data = pd.read_csv(\"../data/transient_pred/P1_log.csv\")\n","pred_Data.shape"],"metadata":{"id":"QwBMhjxbri7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valiables = [\"h1_log\",\n","             \"h2_log\",\n","             \"Eturb_log\",\n","             \"omega_log\",\n","             \"P1_log\",\n","             \"P2_log\",\n","            \"Pout_log\",\n","             \"rho1_log\",\n","             \"rho2_log\",\n","             \"T1_log\",\n","             \"T2_log\",\n","             \"Tboil_log\",\n","             \"x1_log\",\n","             \"x2_log\"\n","             ]"],"metadata":{"id":"1fUk-zpPyAvU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_mse = []\n","total_mape = []\n","score = []\n","for val in valiables:\n","    path = \"../data/transient_pred/\" +  val + \".csv\"\n","    pred_Data = pd.read_csv(path)\n","    Y = pred_Data.iloc[0:len(data), 0:500].values\n","    Xtrain, Xvalid, Xtest, Ytrain, Yvalid, Ytest = split(X, Y)\n","    X_train = torch.from_numpy(Xtrain.astype(np.float32))\n","    y_train = torch.from_numpy(Ytrain.astype(np.float32))\n","    X_valid = torch.from_numpy(Xvalid.astype(np.float32))\n","    y_valid = torch.from_numpy(Yvalid.astype(np.float32))\n","    X_test = torch.from_numpy(Xtest.astype(np.float32))\n","    y_test = torch.from_numpy(Ytest.astype(np.float32))\n","\n","    train = TensorDataset(X_train,y_train)\n","    valid = TensorDataset(X_valid,y_valid)\n","    test = TensorDataset(X_test,y_test)\n","\n","    trainloader = torch.utils.data.DataLoader(train, batch_size=300, shuffle=True, num_workers=1)\n","    validloader = torch.utils.data.DataLoader(valid, batch_size=300, shuffle=False, num_workers=1)\n","    testloader = torch.utils.data.DataLoader(test, batch_size=300, shuffle=False, num_workers=1)\n","\n","    mlp = MLP()\n","    loss_function = nn.MSELoss()\n","    optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-2)\n","    epochs = 50\n","    for t in range(epochs):\n","        if (t % 10 ==0):\n","            print(f\"Epoch {t+1}\\n-------------------------------\")\n","        train_model(trainloader, mlp, loss_function, optimizer, t)\n","        if (t % 10 ==0):\n","            test_model(validloader, mlp, loss_function)\n","\n","    total_mse.append(((loss_function(y_test, mlp(X_test)) / output_size ) ** 0.5).item())\n","    pred = predict_model(X_test, mlp)\n","    # if score == []:\n","    #     score = MAPE(y_test, pred)\n","    # else:\n","    #     score = np.stack([score, [MAPE(y_test, pred)]])\n","    total_mape.append(np.mean(MAPE(y_test, pred)))\n","    score.append(MAPE(y_test, pred))\n","    print(val + \" Done!\")"],"metadata":{"id":"hNz5a3qvU2GG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_mse"],"metadata":{"id":"VRge-FEuwc1e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_mape"],"metadata":{"id":"ieVKRs-vvW5F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.array(score)"],"metadata":{"id":"WOV3dpoKqLae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","t = range(output_size)\n","plt.plot(t, y_test[10])\n","plt.plot(t, pred[10])"],"metadata":{"id":"VRmONAmAt5Gc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(15, 8))\n","medianprops = dict(linewidth=3, color='red')\n","meanprops = dict(marker='X', markerfacecolor='black', markersize=9,markeredgecolor='none')\n","bp = ax.boxplot(score[0:11], labels = valiables[0:11], medianprops=medianprops, showmeans=True, meanprops=meanprops)\n","ax.set_ylim([0, 2])\n","# plt.title('Prediction Score by Variables(MAPE)')\n","ax.set_xlabel('Variable Name')\n","ax.set_ylabel('Score(MAPE)')\n","plt.rcParams['font.size'] = '15'\n","plt.tight_layout()\n","plt.grid()"],"metadata":{"id":"Y7D20vqEwd7S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean( score[11])"],"metadata":{"id":"G0IWieKQz4ur"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"2aHljqkIR7eK"},"execution_count":null,"outputs":[]}]}